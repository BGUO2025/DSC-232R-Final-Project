{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f269de01-5c07-4a05-b675-24155658653e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baixi Guo, Jason Limfueco, Laura Ngo, Pooja Panchal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f426c4a2-db64-4c6a-a8e5-7202bea59675",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a07159-711c-466b-99e3-ac2c6abfa4a1",
   "metadata": {},
   "source": [
    "Let's set up our spark session and rationale before we attend to uploading and partitiioning our data.\n",
    "It‚Äôs a collection of Amazon customer reviews and metadata for Sports category products sold in the U.S.,\n",
    "with star ratings, review text, and related fields, and it is part of a larger Amazon US customer reviews dataset spanning many product types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "664420e6-f0e9-41c7-8383-cbeb7a692322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing our spark\n",
    "\"\"\"\n",
    "Formula == \n",
    "Executor instances = Total Cores - 1\n",
    "Executor memory = (Total Memory - Driver Memory) / Executor Instances\n",
    "\n",
    "Executor instances = 32 ‚àí 1 = 31\n",
    "Executor memory = (128 ‚àí 2) / 31 ‚âà 4.06GB ‚Üí 4GB per executor\n",
    "\n",
    "NOTE:\n",
    "The execution size was the driving factor for this set based on previous experience \\\n",
    "working with social media analysis.\n",
    "Given the 54GB size of the Amazon dataset, this configuration provides:\n",
    "\n",
    "-High parallelism (31 concurrent tasks)\n",
    "-Sufficient executor memory to reduce shuffle spill\n",
    "-Balanced memory distribution to prevent executor OOM during aggregations\n",
    "\n",
    "The 4GB executor size was chosen to provide adequate memory headroom for groupBy and \\\n",
    "aggregation operations without creating excessively large JVM heaps, \\\n",
    "which can increase garbage collection overhead.\n",
    "\"\"\"\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName('amazon_set')\n",
    "    .config('spark.driver.memory', '2g')\n",
    "    .config('spark.executor.instances', '31')\n",
    "    .config('spark.executor.memory', '4g')\n",
    "    .config('spark.executor.cores', '1')\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4a3bb34-7eec-4286-81de-c1bebfb22410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>totalCores</th>\n",
       "      <th>maxMemory</th>\n",
       "      <th>activeTasks</th>\n",
       "      <th>isActive</th>\n",
       "      <th>maxMemory_GB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>driver</td>\n",
       "      <td>32</td>\n",
       "      <td>1099746508</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  totalCores   maxMemory  activeTasks  isActive  maxMemory_GB\n",
       "0  driver          32  1099746508            0      True          1.02"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CHECK IF OUR SPARK SHOWS SOME SORT OF ACTIVE EXECUTOR SET UP\n",
    "import requests\n",
    "import pandas as pd # RECALL we're going to use spark not pandas\n",
    "\n",
    "# Get the active Spark Context and URL\n",
    "sc = spark.sparkContext\n",
    "url = f\"{sc.uiWebUrl}/api/v1/applications/{sc.applicationId}/executors\"\n",
    "\n",
    "# Fetch the executor data from the API\n",
    "response = requests.get(url)\n",
    "executors = response.json()\n",
    "\n",
    "# Format into a readable DataFrame\n",
    "df = pd.DataFrame(executors)[['id', 'totalCores', 'maxMemory', 'activeTasks', 'isActive']]\n",
    "df['maxMemory_GB'] = (df['maxMemory'] / (1024**3)).round(2)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5da3710b-1f8b-49a8-9b49-7909df7f79b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import (\n",
    "    StructType, StructField,\n",
    "    StringType, IntegerType\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0524fbf4-5eb1-41c1-923e-014b1a9ec945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded to: /home/jlimfueco/.cache/kagglehub/datasets/cynthiarempel/amazon-us-customer-reviews-dataset/versions/9\n",
      "+--------+-----------+----------+\n",
      "|category|star_rating|product_id|\n",
      "+--------+-----------+----------+\n",
      "|Apparel |4          |B01KL6O72Y|\n",
      "|Apparel |5          |B01ID3ZS5W|\n",
      "|Apparel |5          |B01I497BGY|\n",
      "|Apparel |5          |B01HDXFZK6|\n",
      "|Apparel |5          |B01G6MBEBY|\n",
      "|Apparel |5          |B01FWRXN0Y|\n",
      "|Apparel |5          |B01EXNH1HE|\n",
      "|Apparel |4          |B01E7OL09O|\n",
      "|Apparel |5          |B01DXHX81O|\n",
      "|Apparel |3          |B01DDULIJK|\n",
      "+--------+-----------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "\n",
    "# Download dataset (cached by kagglehub)\n",
    "base_dir = kagglehub.dataset_download('cynthiarempel/amazon-us-customer-reviews-dataset')\n",
    "print('Downloaded to:', base_dir)\n",
    "\n",
    "# Schema (recommended)\n",
    "schema = StructType([\n",
    "    StructField('marketplace', StringType(), True),\n",
    "    StructField('customer_id', StringType(), True),\n",
    "    StructField('review_id', StringType(), True),\n",
    "    StructField('product_id', StringType(), True),\n",
    "    StructField('product_parent', StringType(), True),\n",
    "    StructField('product_title', StringType(), True),\n",
    "    StructField('product_category', StringType(), True),\n",
    "    StructField('star_rating', IntegerType(), True),\n",
    "    StructField('helpful_votes', IntegerType(), True),\n",
    "    StructField('total_votes', IntegerType(), True),\n",
    "    StructField('vine', StringType(), True),\n",
    "    StructField('verified_purchase', StringType(), True),\n",
    "    StructField('review_headline', StringType(), True),\n",
    "    StructField('review_body', StringType(), True),\n",
    "    StructField('review_date', StringType(), True),\n",
    "])\n",
    "\n",
    "pattern = f'file:{base_dir}/amazon_reviews_us_*_v*.tsv'\n",
    "\n",
    "reviews_df = (\n",
    "    spark.read\n",
    "        .option('header', 'true')\n",
    "        .option('sep', '\\t')\n",
    "        .schema(schema)\n",
    "        .csv(pattern)\n",
    "        .withColumn('source_file', F.input_file_name())\n",
    "        .withColumn('category', F.regexp_extract('source_file', r'amazon_reviews_us_([^/]+?)_v', 1))\n",
    "        .filter(F.col('category') != 'multilingual')\n",
    "        .drop('source_file')\n",
    ")\n",
    "\n",
    "reviews_df.select('category', 'star_rating', 'product_id').show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29bad554-e0ef-42bc-97db-80fe5b070e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partitions: 384\n",
      "+----------------------+-------+\n",
      "|category              |count  |\n",
      "+----------------------+-------+\n",
      "|Wireless              |9002021|\n",
      "|PC                    |6908554|\n",
      "|Apparel               |5906333|\n",
      "|Health_Personal_Care  |5331449|\n",
      "|Beauty                |5115666|\n",
      "|Digital_Ebook_Purchase|5101693|\n",
      "|Video_DVD             |5069140|\n",
      "|Mobile_Apps           |5033376|\n",
      "|Toys                  |4864249|\n",
      "|Sports                |4850360|\n",
      "+----------------------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Partitions:', reviews_df.rdd.getNumPartitions())\n",
    "\n",
    "reviews_df.groupBy('category') \\\n",
    "    .count() \\\n",
    "    .orderBy(F.desc('count')) \\\n",
    "    .show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afcd182a-fbca-49f6-a469-1ef1eeedea27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- marketplace: string (nullable = true)\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- review_id: string (nullable = true)\n",
      " |-- product_id: string (nullable = true)\n",
      " |-- product_parent: string (nullable = true)\n",
      " |-- product_title: string (nullable = true)\n",
      " |-- product_category: string (nullable = true)\n",
      " |-- star_rating: integer (nullable = true)\n",
      " |-- helpful_votes: integer (nullable = true)\n",
      " |-- total_votes: integer (nullable = true)\n",
      " |-- vine: string (nullable = true)\n",
      " |-- verified_purchase: string (nullable = true)\n",
      " |-- review_headline: string (nullable = true)\n",
      " |-- review_body: string (nullable = true)\n",
      " |-- review_date: string (nullable = true)\n",
      " |-- category: string (nullable = false)\n",
      "\n",
      "master: local[*]\n",
      "partitions: 384\n"
     ]
    }
   ],
   "source": [
    "reviews_df.printSchema()\n",
    "print('master:', spark.sparkContext.master)\n",
    "print('partitions:', reviews_df.rdd.getNumPartitions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "007d14d4-faa5-44a1-9430-5a705e6eb62e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102899354"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's... see how big this data is!\n",
    "reviews_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "338fa592-d891-486c-bdcb-47ee85218d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+--------------------+--------------+--------------------+-------------------+--------------------+--------------------+-----------------+------------------+-----------------+---------+-----------------+--------------------+--------------------+-----------+---------+\n",
      "|summary|marketplace|         customer_id|     review_id|          product_id|     product_parent|       product_title|    product_category|      star_rating|     helpful_votes|      total_votes|     vine|verified_purchase|     review_headline|         review_body|review_date| category|\n",
      "+-------+-----------+--------------------+--------------+--------------------+-------------------+--------------------+--------------------+-----------------+------------------+-----------------+---------+-----------------+--------------------+--------------------+-----------+---------+\n",
      "|  count|  102899354|           102899354|     102899354|           102899354|          102899354|           102899354|           102897602|        102897561|         102897561|        102897561|102897561|        102897561|           102897322|           102887488|  102891724|102899354|\n",
      "|   mean|       NULL| 2.833727936438536E7|          NULL|1.4258244766243584E9|5.003337964375594E8|                 NaN|                NULL|4.162648160338805|1.9020360161889551|2.536008594022943|     NULL|             NULL|                 NaN|            Infinity|       NULL|     NULL|\n",
      "| stddev|       NULL|1.5723536662173402E7|          NULL|1.9362264182029324E9| 2.88790890535497E8|                 NaN|                NULL|1.286758530247085|20.772935235587735|22.44830756465268|     NULL|             NULL|                 NaN|                 NaN|       NULL|     NULL|\n",
      "|    min|         US|              100000|R100007TERQ36I|          0000000078|          100000041|        Fine in Time|          2002-08-07|                1|                 0|                0|        N|                N|\\tAll was good :)...|\u0002________________...| 1995-06-24|  Apparel|\n",
      "|    max|         US|             9999996| RZZZZYOFYZ829|          BT00IU6O8K|          999999945|üå¥ Vacation On Th...|\\\\\"Red Spring Blo...|                5|             47524|            48362|        Y|                Y|ü§πüèΩ‚Äç‚ôÇÔ∏èüé§Great pr...|üõÖüöëüööüöèüöôüöàüöòüöà?...| 2015-08-31| Wireless|\n",
      "+-------+-----------+--------------------+--------------+--------------------+-------------------+--------------------+--------------------+-----------------+------------------+-----------------+---------+-----------------+--------------------+--------------------+-----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reviews_df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3b0a924-3468-4381-afa1-16db7336608d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+------------+\n",
      "|product_category      |review_count|\n",
      "+----------------------+------------+\n",
      "|Wireless              |9001881     |\n",
      "|PC                    |6908551     |\n",
      "|Apparel               |5906322     |\n",
      "|Health & Personal Care|5331215     |\n",
      "|Beauty                |5115452     |\n",
      "|Digital_Ebook_Purchase|5101676     |\n",
      "|Video DVD             |5069136     |\n",
      "|Mobile_Apps           |5033376     |\n",
      "|Toys                  |4864243     |\n",
      "|Sports                |4849563     |\n",
      "+----------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's play with the data. What are our most popular products?\n",
    "\n",
    "top_categories = (\n",
    "    reviews_df\n",
    "    .groupBy('product_category')\n",
    "    .agg(F.count('*').alias('review_count'))\n",
    "    .orderBy(F.desc('review_count'))\n",
    "    .limit(10)\n",
    ")\n",
    "\n",
    "top_categories.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05850801-b045-4a02-a06d-4424e147ec0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sports reviews: 4849563\n"
     ]
    }
   ],
   "source": [
    "# How many sports products do we have?\n",
    "sports_count = (\n",
    "    reviews_df\n",
    "    .filter(F.col('product_category') == 'Sports')\n",
    "    .count()\n",
    ")\n",
    "\n",
    "print(f\"Total Sports reviews: {sports_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "585413ab-e8cc-4542-b7e6-92e15bb869c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct Sports products: 1046129\n"
     ]
    }
   ],
   "source": [
    "# How about if we check for the unique sports products by product_id\n",
    "\n",
    "distinct_sports_products = (\n",
    "    reviews_df\n",
    "    .filter(F.col('product_category') == 'Sports')\n",
    "    .select('product_id')\n",
    "    .distinct()\n",
    "    .count()\n",
    ")\n",
    "\n",
    "print(f'Distinct Sports products: {distinct_sports_products}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
